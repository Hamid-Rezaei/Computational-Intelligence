{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq5sNzGGi2Gf"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iyyToMD1izQ4",
    "ExecuteTime": {
     "end_time": "2023-12-18T17:55:59.377449300Z",
     "start_time": "2023-12-18T17:55:55.540884800Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kPei2V5aGFj"
   },
   "source": [
    "## For Google Colab Users\n",
    "\n",
    "This cell is for mounting your Google Drive to the Colab Notebook. If you are not using Google Colab, you can skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d0lQY8oSaJ0"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8gvAZZ9Fjv31",
    "ExecuteTime": {
     "end_time": "2023-12-18T17:55:59.398219900Z",
     "start_time": "2023-12-18T17:55:59.381112400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'cpu'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check for GPU in mac\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc1Ga5_MmtOT"
   },
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE19W1MAv_6W"
   },
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eb0rjSZWmnlN",
    "ExecuteTime": {
     "end_time": "2023-12-18T17:56:50.280635200Z",
     "start_time": "2023-12-18T17:56:50.262343700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "\n",
    "    'Training' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'Testing': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEQ5zz64wRuM"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "79gT4HqIwh96",
    "ExecuteTime": {
     "end_time": "2023-12-18T18:53:33.693911500Z",
     "start_time": "2023-12-18T18:53:33.614668600Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m dataloaders \u001B[38;5;241m=\u001B[39m {x: torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(image_datasets[x], batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data_transforms}\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m### END CODE HERE\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m dataset_sizes \u001B[38;5;241m=\u001B[39m \u001B[43m{\u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mimage_datasets\u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m}\u001B[49m\n\u001B[0;32m     19\u001B[0m class_names \u001B[38;5;241m=\u001B[39m image_datasets[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mclasses\n\u001B[0;32m     21\u001B[0m dataset_sizes, class_names\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# directory: where training and testing data are\n",
    "base_path = os.getcwd()\n",
    "data_dir = os.path.join(base_path, 'Datasets/TumorDataset')\n",
    "\n",
    "### START CODE HERE\n",
    "\n",
    "# datasets.ImageFolder: (https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)\n",
    "# torch.utils.data.DataLoader: (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "\n",
    "# image_datasets are dictionary of (type of dataset, dataloader)\n",
    "# type of dataset are training and testing\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in data_transforms}\n",
    "\n",
    "# DataLoader helps us for better performance and experience in data loading\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in data_transforms}\n",
    "### END CODE HERE\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in None}\n",
    "class_names = image_datasets['Training'].classes\n",
    "\n",
    "dataset_sizes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GImh9haJ0_CN"
   },
   "source": [
    "## Samples of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZzAK1l3y1Tk"
   },
   "outputs": [],
   "source": [
    "samples, labels = next(iter(dataloaders['Testing']))\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.axis('off')\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i+1)\n",
    "    plt.imshow(samples[i].permute(1, 2, 0))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Q-LEGY1P_T"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlhrp8mU1mA-"
   },
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSBfR1g51oVi"
   },
   "outputs": [],
   "source": [
    "# Loading are pretrained model in this task our model is resnet50 (https://www.youtube.com/watch?v=mGMpHyiN5lk)\n",
    "### START CODE HERE\n",
    "\n",
    "# Loading pretrained model\n",
    "model = models.resnet50(pretrained=None)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "### END CODE HERE\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGVAHQqE16mN"
   },
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIVyMWO111cV"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "# You have to change the (fc) layer of the model to compatible with your data\n",
    "model.fc = nn.Linear(model.fc.in_features, None)\n",
    "\n",
    "### END CODE HERE\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybTYDJFw3Zvu"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK2lRW9M3oqU"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKH6IFcj3sBy"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIN1OsTL32Lu"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02TRqi3j3vBa"
   },
   "outputs": [],
   "source": [
    "# you have to change it for better performance\n",
    "optimizer = optim.Adam(model.parameters(), lr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8Ulk0xEvIJN"
   },
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kCVzWjPvMh-"
   },
   "outputs": [],
   "source": [
    "# you can have other thongs like learning rate scheduler and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T4qQCAo37ZN"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaimiD3B4ILt"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "losses = []\n",
    "EPOCH = None\n",
    "\n",
    "# for training part you have to set model to train mode\n",
    "model.train()\n",
    "\n",
    "# loop on epochs\n",
    "for e in tqdm(range(EPOCH)):\n",
    "\n",
    "  # loop on batches\n",
    "  for inputs, labels in dataloaders[None]:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # set the grad to zero\n",
    "    optimizer.None\n",
    "    \n",
    "    # forward part\n",
    "    # hint: using of pytorch max method (https://pytorch.org/docs/stable/generated/torch.max.html)\n",
    "    outputs = model(None)\n",
    "    _, preds = None\n",
    "\n",
    "    #  compute loss\n",
    "    loss = criterion(None, None)\n",
    "    \n",
    "    # backward part\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "  # you have to append loss for each epoch\n",
    "  losses.append(None)\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wked8jWxwvF6"
   },
   "source": [
    "## Plot loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GfAppV85Bhd"
   },
   "outputs": [],
   "source": [
    "# you have to calculate losses arrayin Train part\n",
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9NF0ICIygXC"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DtYxBrp8_5X"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "def calc_accuracy(data, model):\n",
    "  corrects = 0\n",
    "\n",
    "  # for testing part you have to set model to eval mode\n",
    "  model.eval()\n",
    "  for inputs, labels in tqdm(dataloaders[data]):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        outputs = model(None)\n",
    "        _, preds = None\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "  return corrects.double() / dataset_sizes[data]\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEczQlhSDH8s"
   },
   "outputs": [],
   "source": [
    "# accuracy of training data\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaBRMH8GDK4w"
   },
   "outputs": [],
   "source": [
    "# accuracy of testing data\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgfDRa6pzjur"
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axaIXsCMzhPp"
   },
   "outputs": [],
   "source": [
    "PATH = os.path.join(base_path, 'model.ci')\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPZGSYXQ0CkV"
   },
   "source": [
    "# Loading and eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WH_sGX30G-Q"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "model_for_eval = torch.load(PATH)\n",
    "model_for_eval.to(device)\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34pzOFb51ooA"
   },
   "outputs": [],
   "source": [
    "model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvhXDIv90dln"
   },
   "outputs": [],
   "source": [
    "# accuracy of training data by loadded model\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YX6vykni0eL9"
   },
   "outputs": [],
   "source": [
    "# accuracy of testing data by loadded model\n",
    "calc_accuracy(None, None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
